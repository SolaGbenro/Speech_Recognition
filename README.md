# Speech_Recognition

First we extract the *Mel-Frequency Cepstral Coefficients (MFCCs)* from the audio data, then train a deep *Convulutional Neural Network (CNN)* over those features to predict the speaker. The dataset contains 60 samples from 24 individual actors and is available from [kaggle here](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio).

### RESULTS

